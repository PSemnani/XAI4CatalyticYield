{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87008082-5705-4179-bec2-7d62476d9b46",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate ML framework for tree ensamble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b911db-1152-413d-b91f-0382b4174494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from skopt.plots import plot_convergence\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import xgboost.sklearn as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from itertools import product\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "import os\n",
    "from mlxai4cat.utils.data import prepare_dataset, stratified_sampling, resampling \n",
    "from mlxai4cat.utils.visualization import get_formatted_results, plot_feature_importance, plot_feature_importance_distribution\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"skopt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a16bfd-65b8-4a1d-ba2e-caaa18702041",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff79ee-3318-4997-900a-6e533afa62f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef7ea8f-c36c-4eea-a694-eec4ac66c10f",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6417de-7094-47b8-80a0-b5b6e4674451",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X, y, X_pos, y_pos, X_neg, y_neg, feature_names = prepare_dataset('../data/ocm_cat_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa698247-e9fd-4747-80fa-550de9d8f28b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8386c14-0a82-4be2-aa7a-2232d1fabafb",
   "metadata": {},
   "source": [
    "### Training and nested-cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f8327-207a-4278-9ac0-d924f8b9d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "acc_forest = []\n",
    "precision_forest = []\n",
    "recall_forest = []\n",
    "f1_forest = []\n",
    "max_depth_rf = []\n",
    "n_estimators_rf = []\n",
    "min_samples_split_rf = []\n",
    "min_samples_leaf_rf = []\n",
    "feature_importances_forest = []\n",
    "\n",
    "# Loop through different random splits\n",
    "for rs in range(n):\n",
    "    X_train, y_train, X_test, y_test = stratified_sampling(X_pos, X_neg, y_pos, y_neg, rs * 1234 + 567)\n",
    "    X_train, y_train = resampling(X_train, y_train, overratio=0.6, underratio=1, randomstate=123)\n",
    "\n",
    "    clf_forest = RandomForestClassifier(random_state=0)\n",
    "    space = [Integer(1, 10, name='max_depth'),\n",
    "             Integer(50, 500, name='n_estimators'),\n",
    "             Integer(2, 20, name='min_samples_split'),\n",
    "             Integer(1, 20, name='min_samples_leaf')]\n",
    "    \n",
    "    @use_named_args(space)\n",
    "    def objective(**params): # determine objective for gaussian process optimization - the cross validation score\n",
    "        clf_forest.set_params(**params)\n",
    "        return -np.mean(cross_val_score(clf_forest, X_train, y_train, cv=5, n_jobs=-1, scoring=\"f1\"))\n",
    "        \n",
    "    # optimize hyperparameters with gaussian process minimization\n",
    "    res_gp = gp_minimize(objective, space, n_calls=30, random_state=0)\n",
    "    \n",
    "    clf_forest_optim = RandomForestClassifier(random_state=0, max_depth=res_gp.x[0], n_estimators=res_gp.x[1],\n",
    "                                              min_samples_split=res_gp.x[2], min_samples_leaf=res_gp.x[3])\n",
    "    \n",
    "    max_depth_rf.append(res_gp.x[0])\n",
    "    n_estimators_rf.append(res_gp.x[1])\n",
    "    min_samples_split_rf.append(res_gp.x[2])\n",
    "    min_samples_leaf_rf.append(res_gp.x[3])\n",
    "\n",
    "    clf_forest_optim.fit(X_train, y_train)\n",
    "    y_pred = clf_forest_optim.predict(X_test)\n",
    "\n",
    "    # Store feature importance for this split\n",
    "    feature_importances_forest.append(clf_forest_optim.feature_importances_)\n",
    "\n",
    "    acc_forest.append(accuracy_score(y_test, y_pred))\n",
    "    precision_forest.append(precision_score(y_test, y_pred, zero_division=1))\n",
    "    recall_forest.append(recall_score(y_test, y_pred))\n",
    "    f1_forest.append(f1_score(y_test, y_pred))\n",
    "\n",
    "    if rs % 25 == 0:\n",
    "        print(\"Split %s\" % rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf6025-ead7-41a1-9f3b-53373dc70cac",
   "metadata": {},
   "source": [
    "### Display different performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff76579-7058-4dd1-9505-fc861ed73f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = get_formatted_results(acc_forest, f1_forest, precision_forest, recall_forest, model_name=\"Random forest\", verbose=True, df_metrics=None)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f6df80-4ea3-452a-a98c-0bc5bc4932fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance = plot_feature_importance(feature_importances_forest, feature_names, model_name=\"Random forest\", df_feature_importance=None, savedir='../figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46586cf9-6476-4354-b424-38b9c5bb82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance_distribution(feature_importances_forest, feature_names, \"Random Forest\", color='gray', savedir='../figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b6b74b-031a-43e9-a11e-7a138d3bb048",
   "metadata": {},
   "source": [
    "## Random Forest without Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a38ec56-33e5-49a6-840d-dbf946d35530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH DISTRIBUTION OF feature importance without resampling\n",
    "n = 5\n",
    "acc_forest_nr = []\n",
    "precision_forest_nr = []\n",
    "recall_forest_nr = []\n",
    "f1_forest_nr = []\n",
    "max_depth_rf_nr = []\n",
    "n_estimators_rf_nr = []\n",
    "min_samples_split_rf_nr = []\n",
    "min_samples_leaf_rf_nr = []\n",
    "feature_importances_forest_nr = []\n",
    "\n",
    "# Loop through different random splits\n",
    "for rs in range(n):\n",
    "    # Stratified sampling without resampling\n",
    "    X_train, y_train, X_test, y_test = stratified_sampling(X_pos, X_neg, y_pos, y_neg, rs * 1234 + 567)\n",
    "    \n",
    "    clf_forest = RandomForestClassifier(random_state=0)\n",
    "    space = [Integer(1, 10, name='max_depth'),\n",
    "             Integer(50, 500, name='n_estimators'),\n",
    "             Integer(2, 20, name='min_samples_split'),\n",
    "             Integer(1, 20, name='min_samples_leaf')]\n",
    "\n",
    "    # determine objective for gaussian process optimization - the cross validation score\n",
    "    @use_named_args(space)\n",
    "    def objective(**params):\n",
    "        clf_forest.set_params(**params)\n",
    "        return -np.mean(cross_val_score(clf_forest, X_train, y_train, cv=5, n_jobs=8, scoring=\"f1\"))\n",
    "        \n",
    "    # optimize hyperparameters with gaussian process minimization\n",
    "    res_gp = gp_minimize(objective, space, n_calls=30, random_state=0)\n",
    "    \n",
    "    clf_forest_optim = RandomForestClassifier(random_state=0, max_depth=res_gp.x[0], n_estimators=res_gp.x[1],\n",
    "                                              min_samples_split=res_gp.x[2], min_samples_leaf=res_gp.x[3])\n",
    "    \n",
    "    max_depth_rf_nr.append(res_gp.x[0])\n",
    "    n_estimators_rf_nr.append(res_gp.x[1])\n",
    "    min_samples_split_rf_nr.append(res_gp.x[2])\n",
    "    min_samples_leaf_rf_nr.append(res_gp.x[3])\n",
    "\n",
    "    clf_forest_optim.fit(X_train, y_train)\n",
    "    y_pred = clf_forest_optim.predict(X_test)\n",
    "\n",
    "    # Store feature importance for this split\n",
    "    feature_importances_forest_nr.append(clf_forest_optim.feature_importances_)\n",
    "\n",
    "    acc_forest_nr.append(accuracy_score(y_test, y_pred))\n",
    "    precision_forest_nr.append(precision_score(y_test, y_pred, zero_division=1))\n",
    "    recall_forest_nr.append(recall_score(y_test, y_pred))\n",
    "    f1_forest_nr.append(f1_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8ccd52-9851-46f1-8342-586236baa0d3",
   "metadata": {},
   "source": [
    "### Display different performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3339fe75-ccf3-48dd-a22f-5472c2514cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_nr = get_formatted_results(acc_forest_nr, f1_forest_nr, precision_forest_nr, recall_forest_nr, model_name=\"Random forest\", verbose=True, df_metrics = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e316c99-e074-46b4-bc7f-6546a2a81068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance_nr = plot_feature_importance(feature_importances_forest_nr, feature_names, model_name=\"Random forest\", df_feature_importance=None, savedir='../figures')\n",
    "df_feature_importance_nr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c139d0-47f9-42ad-ba39-354003ae8ee2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b5092-1c07-4730-9524-7f3193e693b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "acc_XGBT = []\n",
    "precision_XGBT = []\n",
    "recall_XGBT = []\n",
    "f1_XGBT = []\n",
    "learning_rate_XGBT = []\n",
    "n_estimators_XGBT = []\n",
    "reg_alphas_XGBT = []\n",
    "reg_lambdas_XGBT = []\n",
    "feature_importances_XGBT = []\n",
    "\n",
    "# Loop through different random splits\n",
    "for rs in range(n):\n",
    "    X_train, y_train, X_test, y_test = stratified_sampling(X_pos, X_neg, y_pos, y_neg, rs * 1234 + 567)\n",
    "    X_train, y_train = resampling(X_train, y_train, overratio=0.6, underratio=1, randomstate=123)\n",
    "\n",
    "    clf_XGBT = xgb.XGBClassifier(random_state=0)\n",
    "    space = [Integer(1, 10, name='max_depth'),\n",
    "             Real(10**-5, 10**0, \"log-uniform\", name='learning_rate'),\n",
    "             Real(10**-5, 10**0, \"log-uniform\", name='reg_alpha'),\n",
    "             Real(10**-5, 10**0, \"log-uniform\", name='reg_lambda'),\n",
    "             Integer(50, 500, name='n_estimators')]\n",
    "    \n",
    "    @use_named_args(space)\n",
    "    def objective(**params):\n",
    "        clf_XGBT.set_params(**params)\n",
    "        return -np.mean(cross_val_score(clf_XGBT, X_train, y_train, cv=5, n_jobs=-1, scoring=\"f1\"))\n",
    "    \n",
    "    res_gp = gp_minimize(objective, space, n_calls=30, random_state=0)\n",
    "    \n",
    "    clf_XGBT_optim = xgb.XGBClassifier(random_state=0, max_depth=res_gp.x[0], learning_rate=res_gp.x[1],\n",
    "                                       reg_alpha=res_gp.x[2], reg_lambda=res_gp.x[3], n_estimators=res_gp.x[4])\n",
    "    \n",
    "    learning_rate_XGBT.append(res_gp.x[1])\n",
    "    n_estimators_XGBT.append(res_gp.x[4])\n",
    "    reg_alphas_XGBT.append(res_gp.x[2])\n",
    "    reg_lambdas_XGBT.append(res_gp.x[3])\n",
    "    \n",
    "    clf_XGBT_optim.fit(X_train, y_train)\n",
    "    y_pred = clf_XGBT_optim.predict(X_test)\n",
    "    \n",
    "    acc_XGBT.append(accuracy_score(y_test, y_pred))\n",
    "    precision_XGBT.append(precision_score(y_test, y_pred, zero_division=1))\n",
    "    recall_XGBT.append(recall_score(y_test, y_pred))\n",
    "    f1_XGBT.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    # Save feature importances for this split\n",
    "    feature_importances_XGBT.append(clf_XGBT_optim.feature_importances_)\n",
    "\n",
    "    if rs % 10 == 0:\n",
    "        print(\"Split %s\" % rs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a313b-f1b3-40d8-9958-91ad4a764677",
   "metadata": {},
   "source": [
    "### Display different performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed5386-ccc7-44cb-ac37-97126638fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = get_formatted_results(acc_XGBT, f1_XGBT, precision_XGBT, recall_XGBT, model_name=\"XGBoost\", verbose=True, df_metrics=df_metrics)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a6f6c-825d-4aeb-979d-b93610a24967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance = plot_feature_importance(feature_importances_XGBT, feature_names, model_name=\"XGBoost\", df_feature_importance=df_feature_importance, savedir='../figures')\n",
    "df_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffffa5a-496f-4680-a3cd-7b457a13b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance_distribution(feature_importances_XGBT, feature_names, \"XGBoost\", color='gray', savedir='../figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c85ffc-7a88-45be-aa52-ac4dccd25196",
   "metadata": {},
   "source": [
    "## XGBoost without Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409821e0-2c28-4774-9c4b-8b5caad9ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "acc_XGBT_nr = []\n",
    "precision_XGBT_nr = []\n",
    "recall_XGBT_nr = []\n",
    "f1_XGBT_nr = []\n",
    "learning_rate_XGBT_nr = []\n",
    "n_estimators_XGBT_nr = []\n",
    "reg_alphas_XGBT_nr = []\n",
    "reg_lambdas_XGBT_nr = []\n",
    "feature_importances_XGBT_nr = []\n",
    "\n",
    "# Loop through different random splits\n",
    "for rs in range(n):\n",
    "    X_train, y_train, X_test, y_test = stratified_sampling(X_pos, X_neg, y_pos, y_neg, rs * 1234 + 567)\n",
    "\n",
    "    clf_XGBT = xgb.XGBClassifier(random_state=0)\n",
    "    space = [Integer(1, 10, name='max_depth'),\n",
    "             Real(10**-5, 10**0, \"log-uniform\", name='learning_rate'),\n",
    "             Real(10**-5, 10**0, \"log-uniform\", name='reg_alpha'),\n",
    "             Real(10**-5, 10**0, \"log-uniform\", name='reg_lambda'),\n",
    "             Integer(50, 500, name='n_estimators')]\n",
    "    \n",
    "    @use_named_args(space)\n",
    "    def objective(**params):\n",
    "        clf_XGBT.set_params(**params)\n",
    "        return -np.mean(cross_val_score(clf_XGBT, X_train, y_train, cv=5, n_jobs=-1, scoring=\"f1\"))\n",
    "    \n",
    "    res_gp = gp_minimize(objective, space, n_calls=30, random_state=0)\n",
    "    \n",
    "    clf_XGBT_optim = xgb.XGBClassifier(random_state=0, max_depth=res_gp.x[0], learning_rate=res_gp.x[1],\n",
    "                                       reg_alpha=res_gp.x[2], reg_lambda=res_gp.x[3], n_estimators=res_gp.x[4])\n",
    "    \n",
    "    learning_rate_XGBT_nr.append(res_gp.x[1])\n",
    "    n_estimators_XGBT_nr.append(res_gp.x[4])\n",
    "    reg_alphas_XGBT_nr.append(res_gp.x[2])\n",
    "    reg_lambdas_XGBT_nr.append(res_gp.x[3])\n",
    "    \n",
    "    clf_XGBT_optim.fit(X_train, y_train)\n",
    "    y_pred = clf_XGBT_optim.predict(X_test)\n",
    "    \n",
    "    acc_XGBT_nr.append(accuracy_score(y_test, y_pred))\n",
    "    precision_XGBT_nr.append(precision_score(y_test, y_pred, zero_division=1))\n",
    "    recall_XGBT_nr.append(recall_score(y_test, y_pred))\n",
    "    f1_XGBT_nr.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    # Save feature importances for this split\n",
    "    feature_importances_XGBT_nr.append(clf_XGBT_optim.feature_importances_)\n",
    "\n",
    "    if rs % 10 == 0:\n",
    "        print(\"Split %s\" % rs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b022b-4bad-4844-9273-866fbb35f85d",
   "metadata": {},
   "source": [
    "### Display different performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d19bec-55d1-4df1-9aec-8056de48be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_nr = get_formatted_results(acc_XGBT_nr, f1_XGBT_nr, precision_XGBT_nr, recall_XGBT_nr, model_name=\"XGBoost\", verbose=True, df_metrics = df_metrics_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b6d46d-ea12-49b6-8ff1-792fc4ca2fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance_nr = plot_feature_importance(feature_importances_XGBT_nr, feature_names, model_name=\"XGBoost\", df_feature_importance=df_feature_importance_nr, savedir='../figures')\n",
    "df_feature_importance_nr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f6ddd-7070-4a2a-a259-23dc8605474e",
   "metadata": {},
   "source": [
    "### Save tree ensamble models evaluation and importance score results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a8274f-ca59-4de8-b64f-101404a3cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../results'):\n",
    "    os.mkdir('../results')\n",
    "df_metrics.to_csv('../results/RF_metrics_results.csv', index=False)\n",
    "df_metrics_nr.to_csv('../results/RF_metrics_NO_Resampling_results.csv', index=False)\n",
    "df_feature_importance.to_csv('../results/RF_feature_imp_with_sklearn_results.csv', index=False)\n",
    "df_feature_importance_nr.to_csv('../results/RF_feature_imp_with_sklearn_NO_Resampling_results.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

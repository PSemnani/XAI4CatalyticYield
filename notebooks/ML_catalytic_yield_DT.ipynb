{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66c2ca98-8655-49a1-afe3-ba2892706bc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate ML framework for decision tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d878f-c35b-4806-8981-2d89de1a1df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from skopt.plots import plot_convergence\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import xgboost.sklearn as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from itertools import product\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "import os\n",
    "from mlxai4cat.utils.data import prepare_dataset, stratified_sampling, resampling \n",
    "from mlxai4cat.utils.visualization import get_formatted_results, plot_feature_importance, plot_feature_importance_distribution\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"skopt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0adfca-bd45-4542-98d9-b5c52d4305d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308983f7-ade8-4085-a988-805dfc7d8051",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63998531",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, X, y, X_pos, y_pos, X_neg, y_neg, feature_names = prepare_dataset('../data/ocm_cat_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d53e55-e4b3-4d78-b265-f25047e9a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.corr(numeric_only=True)\n",
    "#plot the heatmap of the correlation matrix\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(dataset.corr(numeric_only=True), annot=True, fmt=\".1f\", cmap='coolwarm', center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d3af18-ad01-4382-a52d-045b6746ded7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Checking robustness of decision tree's performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66cf465",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "acc = []\n",
    "f1 =[]\n",
    "\n",
    "# training 100 different decision tree models on random training/test splits \n",
    "for rs in range(n):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = rs*1234+567)\n",
    "    clf = DecisionTreeClassifier(random_state = rs).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    f1.append(f1_score(y_test, y_pred))\n",
    "\n",
    "# print(f'Accuracy scores: {acc}')\n",
    "# print(f'F1 scores: {f1}')\n",
    "print(f'Accuracy scores mean: {np.mean(acc)}')\n",
    "print(f'Accuracy scores standard deviation: {np.std(acc)}')\n",
    "print(f'F1 scores mean: {np.mean(f1)}')\n",
    "print(f'F1 scores mean standard deviation: {np.std(f1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d53e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = ['#377eb8', '#ff7f00', '#4daf4a', '#984ea3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee9187-d179-4dfb-bc6d-a97597039603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.axvline(np.mean(acc), color='black', linestyle='dashed', linewidth=3) # Mean of the distribution\n",
    "plt.axvline(np.mean(f1), color='black', linestyle='dashed', linewidth=3)\n",
    "plt.text(np.mean(acc) - 0.05, 19, f'Mean Acc: {np.mean(acc):.2f}', fontsize=14, color='black')\n",
    "plt.text(np.mean(f1) - 0.05, 16, f'Mean F1: {np.mean(f1):.2f}', fontsize=14, color='black')\n",
    "plt.hist(np.array(acc), bins = 14, color='#c0c0c0', label='Accuracy')\n",
    "plt.hist(np.array(f1), bins = 20, color='#3cb371', label='F1-score')\n",
    "plt.xticks(fontsize= 14) \n",
    "plt.yticks(fontsize= 14) \n",
    "plt.xlabel('Distribution of performance metrics',fontsize= 16)\n",
    "plt.ylabel('Frequency',fontsize= 16)\n",
    "plt.legend(fontsize= 14)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 20)\n",
    "plt.savefig('../figures/first_DT_accuracy_distribution_without_group.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c197b2-b5c7-45ca-8d7d-ae98bc24d460",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stratified sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d6f4c2-d009-47d6-9382-d734fa75a023",
   "metadata": {},
   "source": [
    "In the whole dataset, there are 51 positive catalysts and 240 non-positive catalysts. To avoid extremely unbalanced data in training set or testing set due to random split, we use stratified sampling to ensure the same proportion of postive catalysts in training set and testing set with the orignal data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd46588-f95a-421e-a8c9-03cdb9478f41",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d33ca9-610b-4b2f-a6a5-795382512b2d",
   "metadata": {},
   "source": [
    "To further overcome the class imbalance, we resample the training data set (size=232, Pos:Non_Pos = 41:191) through a combination of oversampling and undersampling. We first do oversampling using the most popular method SMOTE with a ratio of 0.6 = (232/2) : 191. This ratio refers to the desired ratio of the number of samples in the minority class over the number of samples in the majority class after resampling. We then do random undersampling with a ratio of 1 to ensure equal sample size of two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d65db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double checking the resampling process, to find out how many new samples are generated\n",
    "X_train, y_train, X_test, y_test = stratified_sampling(X_pos, X_neg, y_pos, y_neg, rs * 1234 + 567)\n",
    "X_train, y_train = resampling(X_train, y_train, overratio=0.6, underratio=1, randomstate=123)\n",
    "original_indices = []\n",
    "for x in X:\n",
    "    result = np.where(np.all(X_train == x, axis=1))\n",
    "    if result[0].size > 0:\n",
    "        original_indices.append(result[0][0])\n",
    "\n",
    "original_indices = np.unique(original_indices)\n",
    "\n",
    "# Output results\n",
    "if len(original_indices) == len(X):\n",
    "    print(\"All original samples are in the resampled dataset\")\n",
    "else:\n",
    "    num_new_samples = len(X_train) - len(original_indices)\n",
    "    print(f\"There are {num_new_samples} new, synthetically generated samples in the resampled dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4fa357-9d8c-4f41-96dc-aa90295a036b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decision tree training and nested evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b890699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In  this Decision Tree, there are n iterations, each iteration has a different random state. The random state of Decision Tree is fixed to 0, for the purpose of comparison.\n",
    "\n",
    "n = 100\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "acc_tree = []\n",
    "precision_tree = []\n",
    "recall_tree = []\n",
    "f1_tree = []\n",
    "\n",
    "# Initialize a list to store feature importance values for each split\n",
    "feature_importances_tree = []\n",
    "\n",
    "for rs in range(n):\n",
    "    X_train, y_train, X_test, y_test = stratified_sampling(X_pos, X_neg, y_pos, y_neg, rs * 1234 + 567)\n",
    "    X_train, y_train = resampling(X_train, y_train, overratio=0.6, underratio=1, randomstate=123)\n",
    "\n",
    "    clf = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics and store them\n",
    "    acc_tree.append(accuracy_score(y_test, y_pred))\n",
    "    precision_tree.append(precision_score(y_test, y_pred, zero_division=1))\n",
    "    recall_tree.append(recall_score(y_test, y_pred))\n",
    "    f1_tree.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    # Store feature importance for this split\n",
    "    feature_importances_tree.append(clf.feature_importances_)\n",
    "\n",
    "    # Show an example tree for a specific iteration (e.g., 50th iteration)\n",
    "    if rs == 50:\n",
    "        plt.figure(figsize=(30, 15))\n",
    "        plot_tree(clf, filled=False, fontsize=10, feature_names=feature_names)\n",
    "        plt.title(\"A sample decision tree on training set\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b5e060-7b22-4994-b92c-45395e6eb1ed",
   "metadata": {},
   "source": [
    "### Display different performance metrics for the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = get_formatted_results(acc_tree, f1_tree, precision_tree, recall_tree, model_name=\"Decision Tree\", verbose=True, df_metrics = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f2cc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228348d5-171a-4576-833d-1784d9a92c27",
   "metadata": {},
   "source": [
    "### Plot feature importances obtained using the decision tree's own impurity measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0cff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance = plot_feature_importance(feature_importances_tree, feature_names, model_name=\"Decision tree\", df_feature_importance=None, savedir='../figures')\n",
    "df_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a9ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance_distribution(feature_importances_tree, feature_names, \"Decision Tree\", color='gray', savedir='../figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e0e1d-f10b-4f1a-956a-aa8257b9bbfc",
   "metadata": {},
   "source": [
    "### Display distribution of scores using stratified sampling and resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca470d15-fa4d-4063-861d-80ba77217c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.axvline(np.mean(acc_tree), color='black', linestyle='dashed', linewidth=3)\n",
    "plt.axvline(np.mean(f1_tree), color='black', linestyle='dashed', linewidth=3)\n",
    "plt.text(np.mean(acc_tree) - 0.05, 19, f'Mean Acc: {np.mean(acc_tree):.2f}', fontsize=14, color='black')\n",
    "plt.text(np.mean(f1_tree) - 0.05, 16, f'Mean F1: {np.mean(f1_tree):.2f}', fontsize=14, color='black')\n",
    "\n",
    "plt.hist(np.array(acc_tree), bins = 14, color='#c0c0c0', label='Accuracy')\n",
    "plt.hist(np.array(f1_tree), bins = 20, color='#3cb371', label='F1-score')\n",
    "plt.xticks(fontsize= 14) \n",
    "plt.yticks(fontsize= 14) \n",
    "plt.xlabel('Distribution of performance metrics',fontsize= 16)\n",
    "plt.ylabel('Frequency',fontsize= 16)\n",
    "plt.legend(fontsize= 14)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 20)\n",
    "plt.savefig('../figures/pipeline_DT_accuracy_distribution_without_group.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc052dc",
   "metadata": {},
   "source": [
    "## Decision Tree without RESAMPLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0085e8e7-fb5c-4de3-b29c-7a7487b2ce07",
   "metadata": {},
   "source": [
    "### Training and nested-cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa8833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "acc_tree_nr = []\n",
    "precision_tree_nr = []\n",
    "recall_tree_nr = []\n",
    "f1_tree_nr = []\n",
    "feature_importances_tree_nr = []\n",
    "\n",
    "for rs in range(n):\n",
    "    X_train, y_train, X_test, y_test = stratified_sampling(X_pos, X_neg, y_pos, y_neg, rs * 1234 + 567)\n",
    "\n",
    "    clf_nr = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "    y_pred_nr = clf_nr.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics and store them\n",
    "    acc_tree_nr.append(accuracy_score(y_test, y_pred_nr))\n",
    "    precision_tree_nr.append(precision_score(y_test, y_pred_nr, zero_division=1))\n",
    "    recall_tree_nr.append(recall_score(y_test, y_pred_nr))\n",
    "    f1_tree_nr.append(f1_score(y_test, y_pred_nr))\n",
    "    \n",
    "    # Store feature importance for this split\n",
    "    feature_importances_tree_nr.append(clf_nr.feature_importances_)\n",
    "\n",
    "\n",
    "# EVALUATION METRICS\n",
    "# Calculate mean and standard deviation of evaluation metrics\n",
    "mean_acc_tree_nr = np.mean(acc_tree_nr)\n",
    "std_acc_tree_nr = np.std(acc_tree_nr)\n",
    "mean_f1_tree_nr = np.mean(f1_tree_nr)\n",
    "std_f1_tree_nr = np.std(f1_tree_nr)\n",
    "mean_precision_tree_nr = np.mean(precision_tree_nr)\n",
    "std_precision_tree_nr = np.std(precision_tree_nr)\n",
    "mean_recall_tree_nr = np.mean(recall_tree_nr)\n",
    "std_recall_tree_nr = np.std(recall_tree_nr)\n",
    "\n",
    "# Create a list of tuples for the table\n",
    "table_data_nr = [\n",
    "    ('Metric', 'Mean', 'Standard Deviation'),\n",
    "    ('Accuracy', mean_acc_tree_nr, std_acc_tree_nr),\n",
    "    ('F1 Score', mean_f1_tree_nr, std_f1_tree_nr),\n",
    "    ('Precision', mean_precision_tree_nr, std_precision_tree_nr),\n",
    "    ('Recall', mean_recall_tree_nr, std_recall_tree_nr)\n",
    "]\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(table_data_nr, headers='firstrow', tablefmt='fancy_grid'))\n",
    "\n",
    "# Create a dictionary with the data\n",
    "data_nr = {\n",
    "    'Model': ['Decision Tree'],\n",
    "    'Accuracy_Mean': [mean_acc_tree_nr],\n",
    "    'Accuracy_Std': [std_acc_tree_nr],\n",
    "    'F1_Mean': [mean_f1_tree_nr],\n",
    "    'F1_Std': [std_f1_tree_nr],\n",
    "    'Precision_Mean': [mean_precision_tree_nr],\n",
    "    'Precision_Std': [std_precision_tree_nr],\n",
    "    'Recall_Mean': [mean_recall_tree_nr],\n",
    "    'Recall_Std': [std_recall_tree_nr]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df_metrics_nr = pd.DataFrame(data_nr)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_metrics_nr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaaeb3c-4f6e-441b-9522-30fae84c5c29",
   "metadata": {},
   "source": [
    "### Feature importance scores for decision tree without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance_nr = plot_feature_importance(feature_importances_tree_nr, feature_names, model_name=\"Decision tree\", df_feature_importance=None, savedir='../figures')\n",
    "df_feature_importance_nr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d6c58",
   "metadata": {},
   "source": [
    "## DT with Pre-Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2837e184-dc57-45ad-93c7-524101145a2f",
   "metadata": {},
   "source": [
    "### Training and nested-cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70522daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "acc_preprun = []\n",
    "precision_preprun = []\n",
    "recall_preprun = []\n",
    "f1_preprun = []\n",
    "max_depth_preprun = []\n",
    "min_samples_split_preprun = []\n",
    "min_samples_leaf_preprun = []\n",
    "\n",
    "# Initialize a list to store feature importance values for each split\n",
    "feature_importances_preprun = []\n",
    "\n",
    "# Define the objective function for optimization - the average cross-validation loss\n",
    "def objective(params):\n",
    "    max_depth, min_samples_split, min_samples_leaf = params\n",
    "    clf_preprun = DecisionTreeClassifier(\n",
    "        random_state=0, \n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf\n",
    "    )\n",
    "    return -np.mean(cross_val_score(clf_preprun, X_train, y_train, cv=5, n_jobs=-1, scoring=\"f1\"))\n",
    "\n",
    "for rs in range(n):\n",
    "    X_train, y_train, X_test, y_test = stratified_sampling(X_pos, X_neg, y_pos, y_neg, rs * 1234 + 567)\n",
    "    X_train, y_train = resampling(X_train, y_train, overratio=0.6, underratio=1, randomstate=123)\n",
    "\n",
    "    space = [\n",
    "        Integer(1, 10, name='max_depth'),\n",
    "        Integer(2, 20, name='min_samples_split'),\n",
    "        Integer(1, 20, name='min_samples_leaf')\n",
    "    ]\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        res_gp = gp_minimize(objective, space, n_calls=30, random_state=0, n_initial_points=10)\n",
    "\n",
    "    clf_preprun_optim = DecisionTreeClassifier(\n",
    "        random_state=0, \n",
    "        max_depth=res_gp.x[0], \n",
    "        min_samples_split=res_gp.x[1], \n",
    "        min_samples_leaf=res_gp.x[2]\n",
    "    )\n",
    "    max_depth_preprun.append(res_gp.x[0])\n",
    "    min_samples_split_preprun.append(res_gp.x[1])\n",
    "    min_samples_leaf_preprun.append(res_gp.x[2])\n",
    "\n",
    "    clf_preprun_optim.fit(X_train, y_train)\n",
    "    y_pred = clf_preprun_optim.predict(X_test)\n",
    "\n",
    "    acc_preprun.append(accuracy_score(y_test, y_pred))\n",
    "    precision_preprun.append(precision_score(y_test, y_pred, zero_division=1))\n",
    "    recall_preprun.append(recall_score(y_test, y_pred))\n",
    "    f1_preprun.append(f1_score(y_test, y_pred)) \n",
    "    \n",
    "    # Store feature importance for this split\n",
    "    feature_importances_preprun.append(clf_preprun_optim.feature_importances_)\n",
    "\n",
    "    if rs % 10 == 0:\n",
    "        print(\"Split %s\" % rs)\n",
    "    # Show an example tree\n",
    "    if rs == 1:\n",
    "        plt.figure(figsize=(24, 12))\n",
    "        plot_tree(clf_preprun_optim, filled=False, fontsize=6, feature_names=feature_names)\n",
    "        plt.title(\"Decision tree with pre-pruning on training set (random split)\")\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbf5ac-089e-4807-b5a9-42f97ffd2701",
   "metadata": {},
   "source": [
    "### Performance metrics and importance scores for pre-pruned decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5322c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = get_formatted_results(acc_preprun, f1_preprun, precision_preprun, recall_preprun, model_name=\"DT prepruned\", verbose=True, df_metrics=df_metrics)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11fb0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance = plot_feature_importance(feature_importances_preprun, feature_names, model_name=\"DT prepruned\", df_feature_importance=df_feature_importance, savedir='../figures')\n",
    "df_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9510967",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance_distribution(feature_importances_preprun, feature_names, \"Decision Tree with prepruning\", color='gray', savedir='../figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c178cc",
   "metadata": {},
   "source": [
    "## Pre-Pruned DT without Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621d7e0e-fcaa-4df2-b114-b4fa6b8b864e",
   "metadata": {},
   "source": [
    "### Training and nested-cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82374368",
   "metadata": {},
   "outputs": [],
   "source": [
    " n = 100\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "acc_preprun_nr = []\n",
    "precision_preprun_nr = []\n",
    "recall_preprun_nr = []\n",
    "f1_preprun_nr = []\n",
    "max_depth_preprun_nr = []\n",
    "min_samples_split_preprun_nr = []\n",
    "min_samples_leaf_preprun_nr = []\n",
    "\n",
    "# Initialize a list to store feature importance values for each split\n",
    "feature_importances_preprun_nr = []\n",
    "\n",
    "# Define the objective function for optimization - the average cross-validation loss\n",
    "def objective(params):\n",
    "    max_depth, min_samples_split, min_samples_leaf = params\n",
    "    clf_preprun_nr = DecisionTreeClassifier(\n",
    "        random_state=0, \n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf\n",
    "    )\n",
    "    return -np.mean(cross_val_score(clf_preprun_nr, X_train, y_train, cv=5, n_jobs=-1, scoring=\"f1\"))\n",
    "\n",
    "for rs in range(n):\n",
    "    X_train, y_train, X_test, y_test = stratified_sampling(X_pos, X_neg, y_pos, y_neg, rs * 1234 + 567)\n",
    "\n",
    "    space = [\n",
    "        Integer(1, 10, name='max_depth'),\n",
    "        Integer(2, 20, name='min_samples_split'),\n",
    "        Integer(1, 20, name='min_samples_leaf')\n",
    "    ]\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        res_gp = gp_minimize(objective, space, n_calls=30, random_state=0, n_initial_points=10)\n",
    "\n",
    "    clf_preprun_optim_nr = DecisionTreeClassifier(\n",
    "        random_state=0, \n",
    "        max_depth=res_gp.x[0], \n",
    "        min_samples_split=res_gp.x[1], \n",
    "        min_samples_leaf=res_gp.x[2]\n",
    "    )\n",
    "    max_depth_preprun_nr.append(res_gp.x[0])\n",
    "    min_samples_split_preprun_nr.append(res_gp.x[1])\n",
    "    min_samples_leaf_preprun_nr.append(res_gp.x[2])\n",
    "\n",
    "    clf_preprun_optim_nr.fit(X_train, y_train)\n",
    "    y_pred_nr = clf_preprun_optim_nr.predict(X_test)\n",
    "\n",
    "    acc_preprun_nr.append(accuracy_score(y_test, y_pred_nr))\n",
    "    precision_preprun_nr.append(precision_score(y_test, y_pred_nr, zero_division=1))\n",
    "    recall_preprun_nr.append(recall_score(y_test, y_pred_nr))\n",
    "    f1_preprun_nr.append(f1_score(y_test, y_pred_nr)) \n",
    "    \n",
    "    # Store feature importance for this split\n",
    "    feature_importances_preprun_nr.append(clf_preprun_optim_nr.feature_importances_)\n",
    "    if rs % 25 == 0:\n",
    "        print(\"Split %s\" % rs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d093141",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_nr = get_formatted_results(acc_preprun_nr, f1_preprun_nr, precision_preprun_nr, recall_preprun_nr, model_name=\"DT prepruned\", verbose=True, df_metrics = df_metrics_nr)\n",
    "df_metrics_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance_nr = plot_feature_importance(feature_importances_preprun_nr, feature_names, model_name=\"DT prepruned\", df_feature_importance=df_feature_importance_nr, savedir='../figures')\n",
    "df_feature_importance_nr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e097a9-5138-417e-854e-178b8b88e74b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Decision tree with post-pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60938b15-d9db-4ac4-b8f0-c8eb558c94dc",
   "metadata": {},
   "source": [
    "### Training and nested evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b691d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "acc_postprun = []\n",
    "precision_postprun = []\n",
    "recall_postprun = []\n",
    "f1_postprun =[]\n",
    "alpha_postprun =[]\n",
    "feature_importances_postprun = []\n",
    "\n",
    "for rs in range(n):\n",
    "    X_train, y_train, X_test, y_test = stratified_sampling(X_pos, X_neg, y_pos, y_neg, rs * 1234 + 567)\n",
    "    X_train, y_train = resampling(X_train, y_train, overratio=0.6, underratio=1, randomstate=123)\n",
    "\n",
    "    clf = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "    path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "    ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "    clfs_ = []\n",
    "    for ccp_alpha in ccp_alphas:\n",
    "        clf_ = tree.DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "        clf_.fit(X_train, y_train)\n",
    "        clfs_.append(clf_)\n",
    "\n",
    "    clfs_ = clfs_[:-1]\n",
    "    ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    for c in clfs_:\n",
    "        y_train_pred = c.predict(X_train)\n",
    "        y_test_pred = c.predict(X_test)\n",
    "        train_acc.append(accuracy_score(y_train, y_train_pred))\n",
    "        test_acc.append(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "    alpha = ccp_alphas[np.argmax(test_acc)]\n",
    "    alpha_postprun.append(alpha)\n",
    "    clf_postprun = tree.DecisionTreeClassifier(random_state=0, ccp_alpha=alpha)\n",
    "    clf_postprun.fit(X_train, y_train)\n",
    "    y_pred_postprun = clf_postprun.predict(X_test)\n",
    "\n",
    "    acc_postprun.append(accuracy_score(y_test, y_pred_postprun))\n",
    "    precision_postprun.append(precision_score(y_test, y_pred_postprun, zero_division=1))\n",
    "    recall_postprun.append(recall_score(y_test, y_pred_postprun))\n",
    "    f1_postprun.append(f1_score(y_test, y_pred_postprun))\n",
    "\n",
    "    # Store feature importance for this split\n",
    "    feature_importances_postprun.append(clf_postprun.feature_importances_)\n",
    "\n",
    "    if rs % 50 == 0:\n",
    "        print(\"Split %s\" % rs)\n",
    "\n",
    "    # Show an example tree\n",
    "    if rs == 1:\n",
    "        plt.figure(figsize=(24, 12))\n",
    "        plot_tree(clf_postprun, filled=False, fontsize=6, feature_names=feature_names)\n",
    "        plt.title(\"Decision tree with post-pruning on training set (random split)\")\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f60fca-be53-463f-8d9a-f7f5e62b5c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Performance metrics and importance scores for post-pruned decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = get_formatted_results(acc_postprun, f1_postprun, precision_postprun, recall_postprun, model_name=\"DT postpruned\", verbose=True, df_metrics=df_metrics)\n",
    "df_metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8206ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance = plot_feature_importance(feature_importances_postprun, feature_names, model_name=\"DT postpruned\", df_feature_importance=df_feature_importance, savedir='../figures')\n",
    "df_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance_distribution(feature_importances_postprun, feature_names, \"Decision Tree with postpruning\", color='gray', savedir='../figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e719b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = pd.melt(df_feature_importance, id_vars='Feature', var_name='Model', value_name='Importance')\n",
    "\n",
    "# Create a grouped bar plot using Plotly Express\n",
    "fig = px.bar(df_melted, x='Feature', y='Importance', color='Model',\n",
    "             labels={'Importance': 'Feature Importance', 'Model': 'Model'},\n",
    "             title='Feature Importance Comparison',\n",
    "             barmode='group'  # Set barmode to 'group' for grouped bars\n",
    "            )  # Set the width of the bars\n",
    "\n",
    "# Adjust the width of the bars in the layout\n",
    "fig.update_layout(bargap=0.3, bargroupgap=0.3)\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807c4fc8",
   "metadata": {},
   "source": [
    "## Postprune without Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af9d19e-2116-46b8-a5d1-939b6ba82480",
   "metadata": {},
   "source": [
    "### Training and nested evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd62c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of iterations\n",
    "n = 100\n",
    "\n",
    "# Initialize lists for metrics and feature importances\n",
    "acc_postprun_nr = []\n",
    "precision_postprun_nr = []\n",
    "recall_postprun_nr = []\n",
    "f1_postprun_nr = []\n",
    "alpha_postprun_nr = []\n",
    "feature_importances_postprun_nr = []\n",
    "\n",
    "# Loop through iterations\n",
    "for rs in range(n):\n",
    "    # Stratified sampling without resampling\n",
    "    X_train, y_train, X_test, y_test = stratified_sampling(X_pos, X_neg, y_pos, y_neg, rs * 1234 + 567)\n",
    "    \n",
    "    # Decision tree without resampling\n",
    "    clf = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "    \n",
    "    # Cost complexity pruning\n",
    "    path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "    ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "    clfs_ = [tree.DecisionTreeClassifier(random_state=0, ccp_alpha=alpha).fit(X_train, y_train) for alpha in ccp_alphas[:-1]]\n",
    "\n",
    "    # Calculate accuracies for different alphas\n",
    "    train_acc = [accuracy_score(y_train, clf.predict(X_train)) for clf in clfs_]\n",
    "    test_acc = [accuracy_score(y_test, clf.predict(X_test)) for clf in clfs_]\n",
    "    \n",
    "    # Select the alpha with the highest test accuracy\n",
    "    alpha = ccp_alphas[np.argmax(test_acc)]\n",
    "    alpha_postprun_nr.append(alpha)\n",
    "    \n",
    "    # Fit a decision tree with the selected alpha\n",
    "    clf_postprun = tree.DecisionTreeClassifier(random_state=0, ccp_alpha=alpha).fit(X_train, y_train)\n",
    "    y_pred_postprun = clf_postprun.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics and store them\n",
    "    acc_postprun_nr.append(accuracy_score(y_test, y_pred_postprun))\n",
    "    precision_postprun_nr.append(precision_score(y_test, y_pred_postprun, zero_division=1))\n",
    "    recall_postprun_nr.append(recall_score(y_test, y_pred_postprun))\n",
    "    f1_postprun_nr.append(f1_score(y_test, y_pred_postprun))\n",
    "\n",
    "    # Store feature importance for this split\n",
    "    feature_importances_postprun_nr.append(clf_postprun.feature_importances_)\n",
    "\n",
    "    if rs % 25 == 0:\n",
    "        print(\"Split %s\" % rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6300310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_nr = get_formatted_results(acc_postprun_nr, f1_postprun_nr, precision_postprun_nr, recall_postprun_nr, model_name=\"DT postpruned\", verbose=True, df_metrics = df_metrics_nr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ef206",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance_nr = plot_feature_importance(feature_importances_postprun_nr, feature_names, model_name=\"DT postpruned\", df_feature_importance=df_feature_importance_nr, savedir='../figures')\n",
    "df_feature_importance_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a835e901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_melted_nr = pd.melt(df_feature_importance_nr, id_vars='Feature', var_name='Model', value_name='Importance')\n",
    "\n",
    "# Create a grouped bar plot using Plotly Express\n",
    "fig = px.bar(df_melted_nr, x='Feature', y='Importance', color='Model',\n",
    "             labels={'Importance': 'Feature Importance', 'Model': 'Model'},\n",
    "             title='Feature Importance Comparison without Resampling',\n",
    "             barmode='group'  # Set barmode to 'group' for grouped bars\n",
    "            )  # Set the width of the bars\n",
    "\n",
    "# Adjust the width of the bars in the layout\n",
    "fig.update_layout(bargap=0.3, bargroupgap=0.3)\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af36192-fcfb-4acb-a2ad-8d7977054498",
   "metadata": {},
   "source": [
    "### Save decision tree evaluation and importance score results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d31115c-9b62-4cf0-99c4-b1a3a45fac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../results'):\n",
    "    os.mkdir('../results')\n",
    "df_metrics.to_csv('../results/DT_metrics_results.csv', index=False)\n",
    "df_metrics_nr.to_csv('../results/DT_metrics_NO_Resampling_results.csv', index=False)\n",
    "df_feature_importance.to_csv('../results/DT_feature_imp_with_sklearn_results.csv', index=False)\n",
    "df_feature_importance_nr.to_csv('../results/DT_feature_imp_with_sklearn_NO_Resampling_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ba2b25",
   "metadata": {},
   "source": [
    "## DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
